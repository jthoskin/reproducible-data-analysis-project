library(rpart)
plotcp(tree1)
library(caret)
Validated_result_tree<-predict(tree1,newdata = valid_processed_dt,type="class")
Validated_result_tree<-factor(Validated_result_tree,levels = c("W","L","D"))
confusionMatrix(data = Validated_result_tree,reference = valid_processed_dt$OUTCOME,
positive = "W")
knitr::opts_chunk$set(echo = TRUE)
getwd() #Get Working Directory#
setwd("/Users/Jarradhoskin/Sports Analytics/SIA-Analytics-Report/") #Set Working Directory for import#
AFL_Data<-read.csv("data_forStudents.csv") #Import data into Global Enviroment#
str(AFL_Data) #Check structure of Data#
AFL_Data<-AFL_Data[c(2:41,1,42)] # move game status to to 2nd last column#
str(AFL_Data) #show new structure#
library(caret) #activate caret package from library#
set.seed(1234) #set seed for reproducability#
sample<-createDataPartition(y=AFL_Data$OUTCOME,p=0.60,list = FALSE) #split data to create 3 sets#
train<-AFL_Data[sample,] #put 60% of data into training set#
test_val<-AFL_Data[-sample,] #put 40% into test_val to split again#
sample2<-createDataPartition(test_val$OUTCOME,p=0.50,list = FALSE) #split in half for test and vailidation datasets#
validation<-test_val[sample2,] #put 20% of data into validation dataset#
test<-test_val[-sample2,] #put 20% into test dataset#
dim(train) #shows 2141 observations in the training dataset#
dim(validation) #shows 713 observtions in the validation dataset#
dim(test) #shows 713 observtions in the test dataset#
sum(is.na(train)) #shows that there are 14 missing values#
sum(is.na(validation)) #shows that there are 5 missing values
sum(is.na(test)) #shows that there are 2 misisng values#
library(caret) #activate caret package#
prepImp<-preProcess(train[,-42],method = "knnImpute") #set preprocessing method and save in object "prepImp"#
train_processed<-predict(prepImp,train) #apply pre processing method to train data#
valid_processed<-predict(prepImp,validation) #apply pre processing method to Validation data#
test_processed<-predict(prepImp,test) #apply pre processing method to test data#
sum(is.na(train_processed)) #0 missing values now shown#
sum(is.na(valid_processed)) #0 missing values now shown#
sum(is.na(test_processed)) #0 missing values now shown#
unPreProc <- function(preProc, data){
stopifnot(class(preProc) == "preProcess")
stopifnot(class(data) == "data.frame")
for(i in names(preProc$mean)){
tmp <- data[, i] * preProc$std[[i]] + preProc$mean[[i]]
data[, i] <- tmp
}
return(data)
} #this will save the unpreprocessing function to the globale enviroment
train_processed_dt<-unPreProc(prepImp,train_processed) #save unstandardized variables from train set into new object#
valid_processed_dt<-unPreProc(prepImp,valid_processed) #save unstandardized variables from validation set into new object#
test_processed_dt<-unPreProc(prepImp,test_processed) #save unstandardized variables from test set into new object#
nzv<-nearZeroVar(train_processed_dt[,-42]) #check the dataset for features with near zero variance#
nzv #shows no features with near zero variance#
library(rpart)
set.seed(1234)
tree1<-rpart(OUTCOME~.,data=train_processed_dt,method="class",parms=list(split="information"),control=rpart.control(cp=0.01,minisplit=10))
library(rattle)
fancyRpartPlot(tree1,type = 2,sub = "",palettes = c("Reds","Blues"))
printcp(tree1)
library(rpart)
plotcp(tree1)
library(caret)
Validated_result_tree<-predict(tree1,newdata = valid_processed_dt,type="class")
Validated_result_tree<-factor(Validated_result_tree,levels = c("W","L","D"))
valid_processed_dt<-factor(valid_processed_dt$OUTCOME,levels = c("W","L","D"))
confusionMatrix(data = Validated_result_tree,reference = valid_processed_dt$OUTCOME,
positive = "W")
knitr::opts_chunk$set(echo = TRUE)
getwd() #Get Working Directory#
setwd("/Users/Jarradhoskin/Sports Analytics/SIA-Analytics-Report/") #Set Working Directory for import#
AFL_Data<-read.csv("data_forStudents.csv") #Import data into Global Enviroment#
str(AFL_Data) #Check structure of Data#
AFL_Data<-AFL_Data[c(2:41,1,42)] # move game status to to 2nd last column#
str(AFL_Data) #show new structure#
library(caret) #activate caret package from library#
set.seed(1234) #set seed for reproducability#
sample<-createDataPartition(y=AFL_Data$OUTCOME,p=0.60,list = FALSE) #split data to create 3 sets#
train<-AFL_Data[sample,] #put 60% of data into training set#
test_val<-AFL_Data[-sample,] #put 40% into test_val to split again#
sample2<-createDataPartition(test_val$OUTCOME,p=0.50,list = FALSE) #split in half for test and vailidation datasets#
validation<-test_val[sample2,] #put 20% of data into validation dataset#
test<-test_val[-sample2,] #put 20% into test dataset#
dim(train) #shows 2141 observations in the training dataset#
dim(validation) #shows 713 observtions in the validation dataset#
dim(test) #shows 713 observtions in the test dataset#
sum(is.na(train)) #shows that there are 14 missing values#
sum(is.na(validation)) #shows that there are 5 missing values
sum(is.na(test)) #shows that there are 2 misisng values#
library(caret) #activate caret package#
prepImp<-preProcess(train[,-42],method = "knnImpute") #set preprocessing method and save in object "prepImp"#
train_processed<-predict(prepImp,train) #apply pre processing method to train data#
valid_processed<-predict(prepImp,validation) #apply pre processing method to Validation data#
test_processed<-predict(prepImp,test) #apply pre processing method to test data#
sum(is.na(train_processed)) #0 missing values now shown#
sum(is.na(valid_processed)) #0 missing values now shown#
sum(is.na(test_processed)) #0 missing values now shown#
unPreProc <- function(preProc, data){
stopifnot(class(preProc) == "preProcess")
stopifnot(class(data) == "data.frame")
for(i in names(preProc$mean)){
tmp <- data[, i] * preProc$std[[i]] + preProc$mean[[i]]
data[, i] <- tmp
}
return(data)
} #this will save the unpreprocessing function to the globale enviroment
train_processed_dt<-unPreProc(prepImp,train_processed) #save unstandardized variables from train set into new object#
valid_processed_dt<-unPreProc(prepImp,valid_processed) #save unstandardized variables from validation set into new object#
test_processed_dt<-unPreProc(prepImp,test_processed) #save unstandardized variables from test set into new object#
nzv<-nearZeroVar(train_processed_dt[,-42]) #check the dataset for features with near zero variance#
nzv #shows no features with near zero variance#
library(rpart)
set.seed(1234)
tree1<-rpart(OUTCOME~.,data=train_processed_dt,method="class",parms=list(split="information"),control=rpart.control(cp=0.01,minisplit=10))
library(rattle)
fancyRpartPlot(tree1,type = 2,sub = "",palettes = c("Reds","Blues"))
printcp(tree1)
library(rpart)
plotcp(tree1)
library(caret)
Validated_result_tree<-predict(tree1,newdata = valid_processed_dt,type="class")
Validated_result_tree<-factor(Validated_result_tree,levels = c("W","L","D"))
confusionMatrix(data = Validated_result_tree,reference = valid_processed_dt$OUTCOME,
positive = "W")
View(train_processed)
str(train_processed)
View(train_processed)
View(train_processed)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
corMat<-cor(train_processed[,-42])
library(caret)
corMat<-cor(train_processed[,-41:42])
library(caret)
corMat<-cor(train_processed[,-41,-42])
library(caret)
corMat<-cor(train_processed[,(-41:42)])
library(caret)
corMat<-cor(train_processed[,(-41,-42)])
corMat?
?corMat
cor?
?COR
?cor
library(caret)
corMat<-cor(train_processed[c(-41,-42)])
View(corMat)
library(caret)
corMat<-cor(train_processed[c(-41,-42)])
cor.ind<-findCorrelation(corMat,cutoff = 0.8)
library(caret)
corMat<-cor(train_processed[c(-41,-42)])
cor.ind<-findCorrelation(corMat,cutoff = 0.8)
findCorrelation(corMat,cutoff = 0.8)
library(caret)
corMat<-cor(train_processed[c(-41,-42)])
cor.ind<-findCorrelation(corMat,cutoff = 0.8)
findCorrelation(corMat,cutoff = 0.8,names = TRUE)
library(caret)
corMat<-cor(train_processed[c(-41,-42)])
cor.ind<-findCorrelation(corMat,cutoff = 0.8)
findCorrelation(corMat,cutoff = 0.8,names = TRUE)
train_RF<-train_processed[,-cor.ind]
View(train_RF)
library(randomForest)
library(caret)
ControlIRF<-trainControl(method = "cv", number = 10)
set.seed(123)
Rf<-train_RF(OUTCOME~., method = "rf",data=train_RF, trControl=ControlIRF,prox=TRUE,ntree=250)
library(randomForest)
library(caret)
ControlIRF<-trainControl(method = "cv", number = 10)
set.seed(123)
Rf<-train_RF(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250)
knitr::opts_chunk$set(echo = TRUE)
getwd() #Get Working Directory#
setwd("/Users/Jarradhoskin/Sports Analytics/SIA-Analytics-Report/") #Set Working Directory for import#
AFL_Data<-read.csv("data_forStudents.csv") #Import data into Global Enviroment#
str(AFL_Data) #Check structure of Data#
AFL_Data<-AFL_Data[c(2:41,1,42)] # move game status to to 2nd last column#
str(AFL_Data) #show new structure#
library(caret) #activate caret package from library#
set.seed(1234) #set seed for reproducability#
sample<-createDataPartition(y=AFL_Data$OUTCOME,p=0.60,list = FALSE) #split data to create 3 sets#
train<-AFL_Data[sample,] #put 60% of data into training set#
test_val<-AFL_Data[-sample,] #put 40% into test_val to split again#
sample2<-createDataPartition(test_val$OUTCOME,p=0.50,list = FALSE) #split in half for test and vailidation datasets#
validation<-test_val[sample2,] #put 20% of data into validation dataset#
test<-test_val[-sample2,] #put 20% into test dataset#
dim(train) #shows 2141 observations in the training dataset#
dim(validation) #shows 713 observtions in the validation dataset#
dim(test) #shows 713 observtions in the test dataset#
sum(is.na(train)) #shows that there are 14 missing values#
sum(is.na(validation)) #shows that there are 5 missing values
sum(is.na(test)) #shows that there are 2 misisng values#
library(caret) #activate caret package#
prepImp<-preProcess(train[,-42],method = "knnImpute") #set preprocessing method and save in object "prepImp"#
train_processed<-predict(prepImp,train) #apply pre processing method to train data#
valid_processed<-predict(prepImp,validation) #apply pre processing method to Validation data#
test_processed<-predict(prepImp,test) #apply pre processing method to test data#
sum(is.na(train_processed)) #0 missing values now shown#
sum(is.na(valid_processed)) #0 missing values now shown#
sum(is.na(test_processed)) #0 missing values now shown#
unPreProc <- function(preProc, data){
stopifnot(class(preProc) == "preProcess")
stopifnot(class(data) == "data.frame")
for(i in names(preProc$mean)){
tmp <- data[, i] * preProc$std[[i]] + preProc$mean[[i]]
data[, i] <- tmp
}
return(data)
} #this will save the unpreprocessing function to the globale enviroment
train_processed_dt<-unPreProc(prepImp,train_processed) #save unstandardized variables from train set into new object#
valid_processed_dt<-unPreProc(prepImp,valid_processed) #save unstandardized variables from validation set into new object#
test_processed_dt<-unPreProc(prepImp,test_processed) #save unstandardized variables from test set into new object#
nzv<-nearZeroVar(train_processed_dt[,-42]) #check the dataset for features with near zero variance#
nzv #shows no features with near zero variance#
library(rpart)
set.seed(1234)
tree1<-rpart(OUTCOME~.,data=train_processed_dt,method="class",parms=list(split="information"),control=rpart.control(cp=0.01,minisplit=10))
library(rattle)
fancyRpartPlot(tree1,type = 2,sub = "",palettes = c("Reds","Blues"))
printcp(tree1)
library(rpart)
plotcp(tree1)
library(caret)
Validated_result_tree<-predict(tree1,newdata = valid_processed_dt,type="class")
Validated_result_tree<-factor(Validated_result_tree,levels = c("W","L","D"))
confusionMatrix(data = Validated_result_tree,reference = valid_processed_dt$OUTCOME,
positive = "W")
library(caret)
corMat<-cor(train_processed[c(-41,-42)])
cor.ind<-findCorrelation(corMat,cutoff = 0.8)
findCorrelation(corMat,cutoff = 0.8,names = TRUE)
train_RF<-train_processed[,-cor.ind]
library(randomForest)
library(caret)
ControlIRF<-trainControl(method = "cv", number = 10)
set.seed(123)
Rf<-train_RF(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250)
library(randomForest)
library(caret)
ControlIRF<-trainControl(method = "cv", number = 10)
set.seed(123)
Rf<-train(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250)
Rf
plot(varImp(Rf), top = 20, main = "Figure 1. Importance of factors in Match Outcome")
Rf$finalModel
Rf_Pred<-predict(Rf,newdata = valid_processed)
library(caret)
Rf_Pred<-predict(Rf,newdata = valid_processed)
confusionMatrix(data = Rf_Pred,reference = valid_processed$OUTCOME)
library(mactex)
library(linux)
library(LaTex)
install.packages(tinytex)
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
plotcp(tree1)
library(caret) #activate caret package#
Validated_result_tree<-predict(tree1,newdata = valid_processed_dt,type="class") #apply data to validation data to predict match outcomes#
Validated_result_tree<-factor(Validated_result_tree,levels = c("W","L","D")) #convert to factor#
confusionMatrix(data = Validated_result_tree,reference = valid_processed_dt$OUTCOME,
positive = "W")#create confusion matrix to investigate model performance#
Validated_result_tree
?trainControl
library(randomForest) #activate randomForest package#
library(caret) #activate caret Package#
ControlIRF<-trainControl(method = "repeatedcv", number = 10)
set.seed(123)
Rf<-train(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250)
knitr::opts_chunk$set(echo = TRUE)
getwd() #Get Working Directory#
setwd("/Users/Jarradhoskin/Sports Analytics/SIA-Analytics-Report/") #Set Working Directory#
AFL_Data<-read.csv("data_forStudents.csv") #Import data into Global Enviroment#
str(AFL_Data) #Check structure of Data, output hidden in document#
AFL_Data<-AFL_Data[c(2:41,1,42)] # move game status to to 2nd last column#
str(AFL_Data) #show new structure, output hidden in document#
library(caret) #activate caret package from library#
set.seed(1234) #set seed for reproducability#
sample<-createDataPartition(y=AFL_Data$OUTCOME,p=0.60,list = FALSE) #split data to create 3 sets#
train<-AFL_Data[sample,] #put 60% of data into training set#
test_val<-AFL_Data[-sample,] #put 40% into test_val to split again#
sample2<-createDataPartition(test_val$OUTCOME,p=0.50,list = FALSE) #split in half for test and vailidation datasets#
validation<-test_val[sample2,] #put 20% of data into validation dataset#
test<-test_val[-sample2,] #put 20% into test dataset#
dim(train) #shows 2141 observations in the training dataset#
dim(validation) #shows 713 observtions in the validation dataset#
dim(test) #shows 713 observtions in the test dataset#
sum(is.na(train)) #shows that there are 14 missing values#
sum(is.na(validation)) #shows that there are 5 missing values
sum(is.na(test)) #shows that there are 2 misisng values#
library(caret) #activate caret package#
prepImp<-preProcess(train[,-42],method = "knnImpute") #set preprocessing method and save in object "prepImp"#
train_processed<-predict(prepImp,train) #apply pre processing method to train data#
valid_processed<-predict(prepImp,validation) #apply pre processing method to Validation data#
test_processed<-predict(prepImp,test) #apply pre processing method to test data#
sum(is.na(train_processed)) #0 missing values now shown#
sum(is.na(valid_processed)) #0 missing values now shown#
sum(is.na(test_processed)) #0 missing values now shown#
unPreProc <- function(preProc, data){
stopifnot(class(preProc) == "preProcess")
stopifnot(class(data) == "data.frame")
for(i in names(preProc$mean)){
tmp <- data[, i] * preProc$std[[i]] + preProc$mean[[i]]
data[, i] <- tmp
}
return(data)
} #this will save the unpreprocessing function to the globale enviroment
train_processed_dt<-unPreProc(prepImp,train_processed) #save unstandardized variables from train set into new object#
valid_processed_dt<-unPreProc(prepImp,valid_processed) #save unstandardized variables from validation set into new object#
test_processed_dt<-unPreProc(prepImp,test_processed) #save unstandardized variables from test set into new object#
nzv<-nearZeroVar(train_processed_dt[,-42]) #check the dataset for features with near zero variance#
nzv #shows no features with near zero variance#
library(rpart) #activate rpart package#
set.seed(1234) #set seef for reproducibility#
tree1<-rpart(OUTCOME~.,data=train_processed_dt,method="class",parms=list(split="information"),control=rpart.control(cp=0.01,minisplit=10)) #create decison tree with DT train data with 10 split#
library(rattle) #activate rattle package#
fancyRpartPlot(tree1,type = 2,sub = "",palettes = c("Reds","Blues")) #plot decision tree outcome#
library(rpart) #activate rpart package#
plotcp(tree1) #plot decision tree into graph for analysis#
library(caret) #activate caret package#
Validated_result_tree<-predict(tree1,newdata = valid_processed_dt,type="class") #apply data to validation data to predict match outcomes#
Validated_result_tree<-factor(Validated_result_tree,levels = c("W","L","D")) #convert to factor#
confusionMatrix(data = Validated_result_tree,reference = valid_processed_dt$OUTCOME,
positive = "W") #create confusion matrix to investigate model performance#
library(caret)
corMat<-cor(train_processed[c(-41,-42)]) #create corrlation matrix, removing factor variables#
cor.ind<-findCorrelation(corMat,cutoff = 0.8) #find column index of variables that are highly correated#
findCorrelation(corMat,cutoff = 0.8,names = TRUE) #print variable Names#
train_RF<-train_processed[,-cor.ind] #removes collinear variables and save into enviroment as new dataset for Random forest#
library(randomForest) #activate randomForest package#
library(caret) #activate caret Package#
ControlIRF<-trainControl(method = "repeatedcv", number = 10)
set.seed(123)
Rf<-train(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250)
library(randomForest) #activate randomForest package#
library(caret) #activate caret Package#
ControlIRF<-trainControl(method = "repeatedcv", number = 6, repeats = 10) #set cross validation method to repeated K-folds cross validation for less variance and bias#
set.seed(123) #set seed for reproducibility#
Rf<-train(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250)
knitr::opts_chunk$set(echo = TRUE)
getwd() #Get Working Directory#
setwd("/Users/Jarradhoskin/Sports Analytics/SIA-Analytics-Report/") #Set Working Directory#
AFL_Data<-read.csv("data_forStudents.csv") #Import data into Global Enviroment#
str(AFL_Data) #Check structure of Data, output hidden in document#
AFL_Data<-AFL_Data[c(2:41,1,42)] # move game status to to 2nd last column#
str(AFL_Data) #show new structure, output hidden in document#
library(caret) #activate caret package from library#
set.seed(1234) #set seed for reproducability#
sample<-createDataPartition(y=AFL_Data$OUTCOME,p=0.60,list = FALSE) #split data to create 3 sets#
train<-AFL_Data[sample,] #put 60% of data into training set#
test_val<-AFL_Data[-sample,] #put 40% into test_val to split again#
sample2<-createDataPartition(test_val$OUTCOME,p=0.50,list = FALSE) #split in half for test and vailidation datasets#
validation<-test_val[sample2,] #put 20% of data into validation dataset#
test<-test_val[-sample2,] #put 20% into test dataset#
dim(train) #shows 2141 observations in the training dataset#
dim(validation) #shows 713 observtions in the validation dataset#
dim(test) #shows 713 observtions in the test dataset#
sum(is.na(train)) #shows that there are 14 missing values#
sum(is.na(validation)) #shows that there are 5 missing values
sum(is.na(test)) #shows that there are 2 misisng values#
library(caret) #activate caret package#
prepImp<-preProcess(train[,-42],method = "knnImpute") #set preprocessing method and save in object "prepImp"#
train_processed<-predict(prepImp,train) #apply pre processing method to train data#
valid_processed<-predict(prepImp,validation) #apply pre processing method to Validation data#
test_processed<-predict(prepImp,test) #apply pre processing method to test data#
sum(is.na(train_processed)) #0 missing values now shown#
sum(is.na(valid_processed)) #0 missing values now shown#
sum(is.na(test_processed)) #0 missing values now shown#
unPreProc <- function(preProc, data){
stopifnot(class(preProc) == "preProcess")
stopifnot(class(data) == "data.frame")
for(i in names(preProc$mean)){
tmp <- data[, i] * preProc$std[[i]] + preProc$mean[[i]]
data[, i] <- tmp
}
return(data)
} #this will save the unpreprocessing function to the globale enviroment
train_processed_dt<-unPreProc(prepImp,train_processed) #save unstandardized variables from train set into new object#
valid_processed_dt<-unPreProc(prepImp,valid_processed) #save unstandardized variables from validation set into new object#
test_processed_dt<-unPreProc(prepImp,test_processed) #save unstandardized variables from test set into new object#
nzv<-nearZeroVar(train_processed_dt[,-42]) #check the dataset for features with near zero variance#
nzv #shows no features with near zero variance#
library(rpart) #activate rpart package#
set.seed(1234) #set seef for reproducibility#
tree1<-rpart(OUTCOME~.,data=train_processed_dt,method="class",parms=list(split="information"),control=rpart.control(cp=0.01,minisplit=10)) #create decison tree with DT train data with 10 split#
library(rattle) #activate rattle package#
fancyRpartPlot(tree1,type = 2,sub = "",palettes = c("Reds","Blues")) #plot decision tree outcome#
library(rpart) #activate rpart package#
plotcp(tree1) #plot decision tree into graph for analysis#
library(caret) #activate caret package#
Validated_result_tree<-predict(tree1,newdata = valid_processed_dt,type="class") #apply data to validation data to predict match outcomes#
Validated_result_tree<-factor(Validated_result_tree,levels = c("W","L","D")) #convert to factor#
confusionMatrix(data = Validated_result_tree,reference = valid_processed_dt$OUTCOME,
positive = "W") #create confusion matrix to investigate model performance#
library(caret)
corMat<-cor(train_processed[c(-41,-42)]) #create corrlation matrix, removing factor variables#
cor.ind<-findCorrelation(corMat,cutoff = 0.8) #find column index of variables that are highly correated#
findCorrelation(corMat,cutoff = 0.8,names = TRUE) #print variable Names#
train_RF<-train_processed[,-cor.ind] #removes collinear variables and save into enviroment as new dataset for Random forest#
set.seed(123) #set seed for reproducibility#
Rf<-train(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250) #train the random forrest model using the cross validation method from previous chunk#
set.seed(123) #set seed for reproducibility#
Rf<-train(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250) #train the random forrest model using the cross validation method from previous chunk#
set.seed(123) #set seed for reproducibility#
Rf<-train(OUTCOME~., method = "rf", data = train_RF, trControl = ControlIRF,
prox = TRUE, ntree = 250) #train the random forrest model using the cross validation method from previous chunk#
Rf #show Random Forest Model#
Rf$finalModel #show confusion matrix of model#
library(caret) #activate Caret Package#
Rf_Pred<-predict(Rf,newdata = valid_processed) #apply RF model to validation data to predict match Outcomes#
confusionMatrix(data = Rf_Pred,reference = valid_processed$OUTCOME) #create Confusion Matrix#
?plot
plot(varImp(Rf), top = 20, main = "Figure 1. Importance of factors in Match Outcome") #plot variables to show importance to model#
?trainControl
library(caret)
Rf_Final<-predict(Rf,newdata = test_processed)
confusionMatrix(data = Rf_Final,reference = test_processed$OUTCOME)
plot(varImp(Rf), top = 20, main = "Figure 2. Importance of factors in Match Outcome FC")
data.frame(Observed_Wins=test_processed$OUTCOME,Rf_Final)
plot(varImp(Rf), top = 20, main = "Figure 1. Importance of factors in Match Outcome") #plot variables to show importance to model#
plot(varImp(Rf), top = 20, main = "Importance of factors in Match Outcome") #plot variables to show importance to model#
library(rattle) #activate rattle package#
fancyRpartPlot(tree1,type = 2,sub = "",palettes = c("Reds","Blues")) #plot decision tree outcome#
library(rattle) #activate rattle package#
fancyRpartPlot(tree1,type = 2,sub = "",palettes = c("Reds","Blues")) #plot decision tree outcome#
library(rpart) #activate rpart package#
plotcp(tree1) #plot decision tree into graph for analysis#
library(caret) #activate caret package from library#
set.seed(1234) #set seed for reproducability#
sample<-createDataPartition(y=AFL_Data$OUTCOME,p=0.60,list = FALSE) #split data to create 3 sets#
train<-AFL_Data[sample,] #put 60% of data into training set#
test_val<-AFL_Data[-sample,] #put 40% into test_val to split again#
sample2<-createDataPartition(test_val$OUTCOME,p=0.50,
list = FALSE) #split in half for test and vailidation datasets#
validation<-test_val[sample2,] #put 20% of data into validation dataset#
test<-test_val[-sample2,] #put 20% into test dataset#
dim(train) #shows 2141 observations in the training dataset#
dim(validation) #shows 713 observtions in the validation dataset#
dim(test) #shows 713 observtions in the test dataset#
citation(package = "caret")
citation(package = "rpart")
citation(package = "rattle")
citation(package = "randomforest")
citation(package = "randomForest")
?tidy
FileURL<-"https://github.com/jthoskin/SIA-Analytics-Report/blob/master/newData.csv"
download.file(FileURL, "newData.csv", mmethod = "curl")
New_Data<-read.csv("newData.csv")
View(New_Data)
New_Data<-read.csv("newData.csv")
ne_data<-read.csv("newData.csv")
library(readxl)
newData <- read_excel("Sports Analytics/SIA-Analytics-Report/newData.xlsx")
View(newData)
new_data<-read.csv("newData.csv")
new_predict<-predict(Rf,newdata = newdata)
new_predict<-predict(Rf,newdata = newData)
new_predict
data.frame(game_Number=newData$Game,new_predict)
install.packages("vctrs")
View(AFL_Data)
install.packages("elo")
install.packages("tidyverse")
install.packages(ggtext)
remotes::install_github("wilkelab/ggtext")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(dplyr)
library(caret)
library(dplyr)
library(elo)
library(lubridate)
library(tidyverse)
library(dplyr)
library(elo)
library(lubridate)
library(fitzRoy)
library(ggtext)
dat <- update_footywire_stats()
data <- update_footywire_stats()
Player_Data <- update_footywire_stats(check_existing = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(elo)
library(lubridate)
library(fitzRoy)
library(ggtext)
Player_Data <- update_footywire_stats(check_existing = FALSE)
View(Player_Data)
library(ggplot2)
ggplot(data = Player_Data,aes(x=ED,y=DE))+geom_point(size=2,shape=1)+geom_smooth(method="lm",se=FALSE)+theme_bw()+ylab("Disposal Efficency")
ggplot(data = Player_Data,aes(x=K,y=DE))+geom_point(size=2,shape=1)+geom_smooth(method="lm",se=FALSE)+theme_bw()+ylab("Disposal Efficency")
str(Player_Data)
Player_Data_tidy <- Player_Data[, c(1,4,5,6,7,8,10:43)]
View(Player_Data_tidy)
featurePlot(x=Player_Data_tidy[,c(7:9)],y=Player_Data_tidy$DE)
library(caret)
featurePlot(x=Player_Data_tidy[,c(7:9)],y=Player_Data_tidy$DE)
featurePlot(x=Player_Data_tidy[,c(11:29)],y=Player_Data_tidy$DE)
featurePlot(x=Player_Data_tidy[,c(11:29)],y=Player_Data_tidy$DE)
save.image("~/Desktop/Analytics bits and pieces/AFL Player Analysis.RData")
gwd()
getwd()
setwd("~/Documents/Repos/reproducible-data-analysis-project")
